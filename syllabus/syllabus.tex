\documentclass[10pt]{article}

\usepackage[letterpaper, portrait, margin=1.25in]{geometry}

\usepackage{authblk}
\usepackage[yyyymmdd,hhmmss]{datetime}
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{ASTR 598: Astro-statistics and Machine Learning}
\rhead{Winter 2018}
\rfoot{\em \tiny Compiled on \today\ at \currenttime}
\cfoot{\thepage}
\lfoot{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% author-defined commands
\newcommand\about     {\hbox{$\sim$}}
\newcommand\x         {\hbox{$\times$}}
\newcommand\othername {\hbox{$\dots$}}
\def\eq#1{\begin{equation} #1 \end{equation}}
\def\eqarray#1{\begin{eqnarray} #1 \end{eqnarray}}
\def\eqarraylet#1{\begin{mathletters}\begin{eqnarray} #1 %
                  \end{eqnarray}\end{mathletters}}
\def\non    {\nonumber \\}
\def\DS     {\displaystyle}
\def\E#1{\hbox{$10^{#1}$}}
\def\sub#1{_{\rm #1}}
\def\case#1/#2{\hbox{$\frac{#1}{#2}$}}
\def\about  {\hbox{$\sim$}}
\def\x      {\hbox{$\times$}}
\def\ug               {\hbox{$u-g$}}
\def\gr               {\hbox{$g-r$}}
\def\ri               {\hbox{$r-i$}}
\def\iz               {\hbox{$i-z$}}
\def\a                {\hbox{$a^*$}}
\def\O                {\hbox{$O$}}
\def\E                {\hbox{$E$}}
\def\Oa               {\hbox{$O_a$}}
\def\Ea               {\hbox{$E_a$}}
\def\Jg               {\hbox{$J_g$}}
\def\Fg               {\hbox{$F_g$}}
\def\J                {\hbox{$J$}}
\def\F                {\hbox{$F$}}
\def\N                {\hbox{$N$}}
\def\dd               {\hbox{deg/day}}
\def\mic              {\hbox{$\mu{\rm m}$}}
\def\Mo{\hbox{$M_{\odot}$}}
\def\Lo{\hbox{$L_{\odot}$}}
\def\comm#1           {\tt #1}
\def\refto#1          {\ref #1}
\def\T#1              {({\bf #1})}
\def\H#1              {({\it #1})}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\title{{\bf ASTR 598: Astro-statistics and Machine Learning}} 
\author{Andy Connolly \& \v{Z}eljko Ivezi\'{c}}
\affil{University of Washington, Winter Quarter 2018}
\date{\vspace{-5ex}}

\begin{document}
\maketitle

\vskip 0.3in
\leftline{{\bf  Location and Time:} Tuesdays and Thursdays 11:00-12:20, {\bf Room: B305}}

\vskip 0.2in
\leftline{{\bf  Office Hours:} { Any time when our office doors are open; }}
\leftline{\hskip 1.15in After class, or Tue and Thu mornings by appt. are the best.}
\vskip 0.2in
\leftline{{\bf  Class web site:} https://github.com/dirac-institute/uw-astr598-w18} 
\vskip 0.2in
\leftline{\bf  Reference textbook:} 
\leftline{Ivezi\'{c}, Connolly, VanderPlas \& Gray: {\it Statistics, Data Mining, and Machine Learning in Astronomy: }}
\leftline{{\it A Practical Python Guide for the Analysis of Survey Data} (Princeton University Press, 2014)}
\leftline{See http://press.princeton.edu/titles/10159.html}
\vskip 0.3in

{\bf Learning Goals:}
This course will introduce graduate students to most common statistical and computer science methods 
used in astronomy and other physical sciences. It will combine theoretical background with 
examples of data analysis based on modern astronomical datasets. Practical data analysis 
will be done using python tools, such as astroML module (see www.astroML.org). 
While focused on astronomy, this course should be useful to all graduate students interested in data 
analysis in physical sciences and engineering. The lectures will be aimed at graduate 
students and the main discussion topics will be based on Chapters 3-5, and selected 
topics from Chapters 6-10, from the reference textbook. 

By taking this course, students will develop working knowledge of topics such as robust 
statistics, hypothesis testing, maximum likelihood analysis, Bayesian statistics, model 
parameter estimation, the goodness of fit and model selection, density estimation and 
clustering, unsupervised and supervised classification, dimensionality reduction, 
regression and time series analysis. Most of these topics will be applied in class 
homeworks and projects to analysis of astronomical data. 

\vskip 0.2in
{\bf Prerequisites:}
The students taking this class are required to have taken basic calculus and statistics, 
to have knowledge of scientific measurements at the level of a senior lab (in science 
or engineering), as well as to have basic python skills. 

\vskip 0.2in
{\bf Lecture format:}
After a few introductory lectures, new material will be introduced on a schedule that 
will enable independent student work on a publication-quality class project. 

\newpage 
% \vskip 0.2in
\leftline{\bf  Class Schedule (tentative!):}
\begin{itemize}

\item WEEK 0 (first class on Jan 4, \v{Zeljko}): Introduction to class (syllabus, literature, astroML, class project, DataLab) 

\item WEEK 1 (starting Jan 8, \v{Zeljko}): Introduction to statistics (probability, distributions, 
                              robust statistics, Central Limit Theorem, hypothesis testing).

\item WEEK  2 (starting Jan 15): Work on the Class Project  (step 1). 

\item WEEK  3 (starting Jan 22): Maximum likelihood and applications in astronomy.

\item WEEK  4 (starting Jan 29): Bayesian statistics and introduction to MCMC; Class Project step 2 report.

\item WEEK  5 (starting Feb 5): Model parameter estimation and model selection.

\item WEEK  6 (starting Feb 12): Regression and Time series analysis; Class Project step 3 report. 

\item WEEK  7 (starting Feb 19): Dimensionality reduction; Class Project step 4 report. 

\item WEEK  8 (starting Feb 26): Density estimation and clustering; Class Project step 5 report. 

\item WEEK  9 (starting Mar 5): Supervised Classification; writing assignments for Class Project paper 

\item FINAL EXAM: Mar 13 (Tue, 11:00-12:20, B305): cake and closed book final exam.

\end{itemize}

\vskip 0.2in

\leftline{\bf  Class Project}

A quarter-long survey data analysis project is described separately (see the class website). 
We will use GitHub and Jupyter notebooks for progress tracking. 

\end{document}





\item WEEK 0 (first class on Jan 4): 
\item Thu (\v{Zeljko}): Introduction (syllabus, literature, astroML, class project, DataLab) 

\item WEEK 1 (starting Jan 8): 
\begin{itemize} 
\item Tue (\v{Zeljko}): Introduction to statistics (probability, distributions, 
                 robust statistics, Central Limit Theorem,  hypothesis testing).
\item Thu (\v{Zeljko}): 
\end{itemize}     

\item WEEK  2 (starting Jan 15): 
\begin{itemize}
\item Tue (\v{Zeljko}): 
\item Thu: 
\end{itemize}     

\item WEEK  3 (starting Jan 22):  Maximum likelihood and applications in astronomy.
\begin{itemize}
\item Tue: 
\item Thu: 
\end{itemize}     

\item WEEK  4 (starting Jan 29):  Bayesian statistics and introduction to MCMC.
\begin{itemize}
\item Tue: 
\item Thu: 
\end{itemize}     

\item WEEK  5 (starting Feb 5):  Model parameter estimation and model selection.
\begin{itemize}
\item Tue (\v{Zeljko}): 
\item Thu (\v{Zeljko}): 
\end{itemize}     

\item WEEK  6 (starting Feb 12):   Time series analysis.
\begin{itemize}
\item Tue: 
\item Thu: 
\end{itemize}     

\item WEEK  7 (starting Feb 19):   Big data in astronomy.
\begin{itemize}
\item Tue (Mario?): 
\item Thu (Andy?): 
\end{itemize}     

\item WEEK  8 (starting Feb 26): Dimensionality reduction and regression.
\begin{itemize}
\item Tue: 
\item Thu: 
\end{itemize}     

\item WEEK  9 (starting Mar 5):  Density estimation and clustering.
\begin{itemize}
\item Tue (Mario?):  
\item Thu (Mario?):  
\end{itemize}     





From Astr 324: 

Lecture 1: Introduction and warm-up with astroML
Lecture 2: Getting Started with Git etc.
Lecture 3: Introduction to Probability & Statistics. I
Lecture 4: Introduction to Probability & Statistics. II
Lecture 5: Maximum Likelihood and Applications in Astronomy. I
Lecture 6: Maximum Likelihood and Applications in Astronomy. II
Lecture 7: Introduction to Bayesian Inference
Lecture 8: Model Selection in Bayesian Framework
Lecture 9: Parameter estimation and model selection with MCMC. I
Lecture 10: Parameter estimation and model selection with MCMC. II
Lecture 11: Time Series Analysis. I
Lecture 12: Time Series Analysis. II
Lecture 13: Databases. I
Lecture 14: Databases. II
Lecture 15: Principal Component Analysis
Lecture 16: Regression (notebook)
Lecture 17: Density Estimation. I
Lecture 18: Density Estimation. II
Lecture 19: Unsupervised Classification (notebook)
Lecture 20: Supervised Classification (notebook)


